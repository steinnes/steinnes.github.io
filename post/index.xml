<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on steinn.org</title>
    <link>http://steinn.org/post/</link>
    <description>Recent content in Posts on steinn.org</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Mar 2015 01:11:52 +0000</lastBuildDate>
    <atom:link href="http://steinn.org/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>redis workload recorder</title>
      <link>http://steinn.org/post/redis-workload-recorder/</link>
      <pubDate>Thu, 19 Mar 2015 01:11:52 +0000</pubDate>
      
      <guid>http://steinn.org/post/redis-workload-recorder/</guid>
      <description>&lt;p&gt;Recently I&amp;rsquo;ve been working on some redis profiling and research, and since
we run several distinct redis instances at Plain Vanilla (due to reliability
and configuration reasons) the necessity to record a certain amount of commands
for several different redis instances became rather apparent.&lt;/p&gt;

&lt;p&gt;Rather than relying on my usual &lt;code&gt;redis-cli monitor &amp;gt; /some/file&lt;/code&gt; inside a
screen, then remembering to &lt;code&gt;ctrl+c&lt;/code&gt; after say 3600 seconds, I decided to
script this for the benefit of my future self (and maybe others).&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/ead90afa9882e89b995f.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;Usage:
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;screen
&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;./redis-workload-record.py &lt;span style=&#34;color: #ae81ff&#34;&gt;3600&lt;/span&gt; localhost &amp;gt; 3600-sec-redis-something.log
^A d
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;This will start a screen where the workload recorder will run for 3600 seconds.
As can be seen from the code, the exit message will be printed to stderr so
your output can be safely redirected into a file, which then can be read and
replayed by something like this:&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/212f3273d17a7549ac46.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;By running something like this:
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;cat 3600-sec-redis-something.log &lt;span style=&#34;color: #f8f8f2&#34;&gt;|&lt;/span&gt; python redis-pipe-commands.py
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Hope this benefits someone (other than my future self :-)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinventing the wheel</title>
      <link>http://steinn.org/post/reinventing-the-wheel/</link>
      <pubDate>Mon, 09 Mar 2015 16:03:03 +0000</pubDate>
      
      <guid>http://steinn.org/post/reinventing-the-wheel/</guid>
      <description>

&lt;p&gt;We all tend to reinvent the wheel once in a while, and often it&amp;rsquo;s just
a question of not having found the right tool with a quick search, or
better: we prefer doing something differently and/or we enjoy the process
of building something just for the heck of it.  This is a small story of
me being slightly stupid, but also about UDP and how awesome it is :-)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m fond of UDP.  The user datagram protocol.  Unlike it&amp;rsquo;s cousin TCP,
UDP packets do not contain a sequence number and the protocol does not
ack packets.  For practical purposes this means it gets used in scenarios
where latency is more important than reliability: you prefer to lose some
packets, rather than adding any overhead of acknowledging packets or waiting
for packets if they arrive out-of-sequence or get lost on the way.&lt;/p&gt;

&lt;p&gt;When streaming audio or video it&amp;rsquo;s usually better to drop packets (and thus
frames) than to stall a live stream or conversation while syncing up so
streaming applications often use UDP, and it is also commonly used as the
underlying network protocol in FPS games (Quake 3, and probably the other
Quake games spring to mind).&lt;/p&gt;

&lt;p&gt;A major reason for my current love of UDP is because of it&amp;rsquo;s use in StatsD,
a wonderful protocol developed (afaik) at &lt;a href=&#34;https://codeascraft.com/2011/02/15/measure-anything-measure-everything/&#34;&gt;Etsy&lt;/a&gt;
to measure &amp;ldquo;anything and everything&amp;rdquo; in their app.  I came to know StatsD
when I started working for &lt;a href=&#34;http://www.plainvanilla.is&#34;&gt;Plain Vanilla&lt;/a&gt;
who were already using it for monitoring the first single-topic QuizUp
games.  To make a long story short the fire-and-forget approach to massive
amounts of statistical data made my heart stir.&lt;/p&gt;

&lt;h2 id=&#34;a-job-for-udp:45b89691d97c2fd1cd87eabd7efa9032&#34;&gt;A job for UDP!&lt;/h2&gt;

&lt;p&gt;For the last few weeks I&amp;rsquo;ve been working on ways to profile and optimize
&lt;a href=&#34;http://redis.io&#34;&gt;redis&lt;/a&gt; for caching purposes.  The research is
far from conclusive results, but one of the things we needed to do was find
an unobtrusive way to monitor key touches in redis.&lt;/p&gt;

&lt;p&gt;What we decided to do was to patch it to add a &amp;ldquo;key sampling&amp;rdquo; mechanism which
fires UDP packets containing a key when it gets touched.  This allows us to
reather cheaply allow an external program to receive a sampling of key touches
with a minimal performance hit or overhead in redis itself.&lt;/p&gt;

&lt;p&gt;To read this data and pipe it into different analyzers, I hacked up a little
program which listens on an UDP socket and writes anything it receives to
stdout.  Here&amp;rsquo;s a gist of that program:&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/e017ea610a2ee2872e3a.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;I named the gist &amp;ldquo;pointless udp dumper&amp;rdquo;&amp;hellip; so why pointless?&lt;/p&gt;

&lt;p&gt;Well because as a close friend pointed out I could have used &lt;code&gt;netcat&lt;/code&gt;.
My ego was slightly stroked by the fact that he said &amp;ldquo;Ah, I guess you want
to do something more complex later, which is why you don&amp;rsquo;t just use netcat..&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;But the answer was: No, I just keep forgetting that netcat supports UDP,
and these eight bytes (excl. the port!) will do the same as my pointless udp
dumper, on any machine with netcat installed:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;nc -l -u 12345
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;It can be fun to re-invent the wheel, but I must admit that I prefer to do
it consciously :-)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Changing redis maxmemory gradually</title>
      <link>http://steinn.org/post/redis-gradual-maxmemory/</link>
      <pubDate>Sun, 01 Mar 2015 16:28:22 +0000</pubDate>
      
      <guid>http://steinn.org/post/redis-gradual-maxmemory/</guid>
      <description>&lt;p&gt;Today we&amp;rsquo;ve been busy migrating some AWS instances at work due to upcoming
maintenance events in AWS.  One of the instance families we used a lot when
building QuizUp is the m2 instance family and almost all of our m2 instances
will require restarts in the next few days.&lt;/p&gt;

&lt;p&gt;On some of these we are running large redis instances with tens of GB of data
and restarting them is not pain-free, even if we would use the persistence
features of redis, which work by periodically dumping the entire dataset into
a &lt;code&gt;dump.rdb&lt;/code&gt; file.  If the keyspace is tens of GB, the process of saving, and
reading the data is quite slow. Even with a disk subsystem capable of 100MB/s
sustained reads and writes, saving and reading will take around 500 seconds each.&lt;/p&gt;

&lt;p&gt;In the mean time you probably do not want to serve requests.  While saving
because you&amp;rsquo;ll write changes that won&amp;rsquo;t be reflected in the &lt;code&gt;dump.rdb&lt;/code&gt; file, so
you lose data on restart, and while reading the data redis does not allow writes
(at least by default) and even serving reads can be dangerous if your application
makes assumptions based on the availability of keys.&lt;/p&gt;

&lt;p&gt;In order to deal nicely with this scenario we basically slave our redis instances
with newer instance types and then mostly seamlessly failover to them (I can
write another blog post on that later).  Slaving however is not problem-free.&lt;/p&gt;

&lt;p&gt;Until redis 2.8.18 the only way to slave is for the master to start by making a
&lt;code&gt;dump.rdb&lt;/code&gt; file, which when complete gets streamed to the slave, which saves it
to disk, then reads it up from disk, and all writes/changes happening on the
master are buffered in the mean-time.  This causes a series of problems (more
&lt;a href=&#34;http://java.dzone.com/articles/top-redis-headaches-devops&#34;&gt;here&lt;/a&gt;)
which I won&amp;rsquo;t expand on here, but let&amp;rsquo;s suffice to say that the smaller the dataset
is, the easier time you will have making a slave of it.&lt;/p&gt;

&lt;p&gt;If your dataset is mostly volatile, meaning that it&amp;rsquo;s nice to have the data there
but not crucial, lowering the maxmemory down to force redis to evict keys is a
sound strategy to improve your life as a slavemaster.  Today I took a crappy script
I had which does just that and packaged it a little more nicely and it&amp;rsquo;s on GitHub:
&lt;a href=&#34;http://github.com/steinnes/redis-memslider&#34;&gt;steinnes/redis-memslider&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker Workshop</title>
      <link>http://steinn.org/post/docker-workshop/</link>
      <pubDate>Sat, 14 Feb 2015 17:12:57 +0000</pubDate>
      
      <guid>http://steinn.org/post/docker-workshop/</guid>
      <description>

&lt;p&gt;These are the instructions/background I wrote for a workshop on Docker
when we started deploying the backend services for
&lt;a href=&#34;http://www.quizup.com&#34;&gt;QuizUp&lt;/a&gt; as Dockers, in November 2014.&lt;/p&gt;

&lt;h2 id=&#34;what-is-docker:458e3be24730f7f94ff6d0ff1bbbd91d&#34;&gt;What is Docker?&lt;/h2&gt;

&lt;p&gt;It is a server and client for creating lightweight machine images, known
as containers.  Currently these images can be run on Linux, in what are
known as LinuX Containers (LXC).  Docker uses AUFS (a union file system)
and some clever magic to save time when creating new images.&lt;/p&gt;

&lt;h2 id=&#34;how-does-it-do-this:458e3be24730f7f94ff6d0ff1bbbd91d&#34;&gt;How does it do this?&lt;/h2&gt;

&lt;p&gt;On an LXC-capable host, you can run the &amp;ldquo;docker&amp;rdquo; daemon which allows any
docker client to create new images, and start them.  The images are created
using recipe files called &amp;ldquo;Dockerfiles&amp;rdquo;, which look something like this:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt; debian&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;ENV&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt; DEBIAN_FRONTEND noninteractive&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;RUN&lt;/span&gt; apt-get update &lt;span style=&#34;color: #f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y openssh-server
&lt;span style=&#34;color: #66d9ef&#34;&gt;ADD&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt; authorized_keys /root/.ssh/authorized_keys&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;CMD&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt; mkdir -p /var/run/sshd &amp;amp;&amp;amp; exec /usr/sbin/sshd -D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;If situated in a folder with a file called &lt;code&gt;Dockerfile&lt;/code&gt; with the contents
from above, we can build an image based on it using the docker command line
client:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;docker build -t steinn/ssh-docker-1 .
Sending build context to Docker daemon  2.56 kB
Sending build context to Docker daemon
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt; : FROM debian
---&amp;gt; 61f7f4f722fb
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt; : ENV DEBIAN_FRONTEND noninteractive
---&amp;gt; Running in 18c5aa0fa614
---&amp;gt; f7fb51a8a0ec
Removing intermediate container 18c5aa0fa614
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt; : RUN apt-get update &lt;span style=&#34;color: #f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y openssh-server
---&amp;gt; Running in efcaf53c9380
Get:1 http://http.debian.net wheezy Release.gpg &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1655&lt;/span&gt; B&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt;
.... VERY LONG PRINTOUT SUPPRESSED ....
---&amp;gt; 6172db1d263d
Removing intermediate container efcaf53c9380
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt; : CMD mkdir -p /var/run/sshd &lt;span style=&#34;color: #f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;exec&lt;/span&gt; /usr/sbin/sshd -D
---&amp;gt; Running in 446fb44be23e
---&amp;gt; 914c4e3e928b
Removing intermediate container 446fb44be23e
Successfully built 914c4e3e928b
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Note the &lt;code&gt;---&amp;gt;&lt;/code&gt; commands in between &amp;ldquo;Steps&amp;rdquo;.  They are indicating when
Docker is creating a new file system layer, so in effect an image, and stores
it after every step.  This makes it extremely fast to re-run docker builds
unless the build steps change.  Here is the output from the same command as
above, run again, and with &lt;code&gt;time&lt;/code&gt; in front:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ time &lt;/span&gt;docker build -t steinn/ssh-docker-1 .
Sending build context to Docker daemon  2.56 kB
Sending build context to Docker daemon
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt; : FROM debian
---&amp;gt; 61f7f4f722fb
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt; : ENV DEBIAN_FRONTEND noninteractive
---&amp;gt; Using cache
---&amp;gt; f7fb51a8a0ec
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt; : RUN apt-get update &lt;span style=&#34;color: #f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y openssh-server
---&amp;gt; Using cache
---&amp;gt; 6172db1d263d
Step &lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt; : CMD mkdir -p /var/run/sshd &lt;span style=&#34;color: #f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;exec&lt;/span&gt; /usr/sbin/sshd -D
---&amp;gt; Using cache
---&amp;gt; 914c4e3e928b
Successfully built 914c4e3e928b

real        0m0.236s
user        0m0.007s
sys 0m0.008s
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s analyse these messages a bit.  The first one says &amp;ldquo;Sending build
context to Docker daemon  2.56 kB&amp;rdquo;.  What&amp;rsquo;s happening here?  Basically
your docker client is making a tarball of the directory containing your
Dockerfile and all subdirectories, and posting them along with some
metadata to port 2375 of it&amp;rsquo;s Docker host.  The Docker host defaults on
every machine to unix:///var/run/docker.sock, but can be set via the
DOCKER_HOST environment variable to another machine, such as:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ export DOCKER_HOST&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;tcp://192.168.22.8:2375
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;A common approach on OS X machines is to use a set of scripts called
&amp;ldquo;boot2docker&amp;rdquo; which basically give you a very simple interface for
downloading and running a bare-bones linux image with a docker daemon
via virtualbox.  It will even tell you which environment variables to
export.  See:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;$ &lt;/span&gt;boot2docker up
Waiting &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; VM and Docker daemon to start...
.o
Started.
Writing /Users/ses/.boot2docker/certs/boot2docker-vm/ca.pem
Writing /Users/ses/.boot2docker/certs/boot2docker-vm/cert.pem
Writing /Users/ses/.boot2docker/certs/boot2docker-vm/key.pem

To connect the Docker client to the Docker daemon, please &lt;span style=&#34;color: #f8f8f2&#34;&gt;set&lt;/span&gt;:
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export DOCKER_HOST&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;tcp://192.168.59.103:2376
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export DOCKER_CERT_PATH&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;/Users/ses/.boot2docker/certs/boot2docker-vm
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export DOCKER_TLS_VERIFY&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;1
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;h1 id=&#34;exercise:458e3be24730f7f94ff6d0ff1bbbd91d&#34;&gt;Exercise&lt;/h1&gt;

&lt;p&gt;Now that you&amp;rsquo;ve played around with docker a bit. It is time for an exercise.&lt;/p&gt;

&lt;p&gt;A few weeks ago we did a little &amp;ldquo;testing kata&amp;rdquo; which was a Python Flask http
web service for making basic calculations.  Since that is a common problem
(ie. creating and dockerizing a little web service) I decided to base todays
exercise on that.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Go to &lt;a href=&#34;https://github.com/plain-vanilla-games/flask-test-kata&#34;&gt;https://github.com/plain-vanilla-games/flask-test-kata&lt;/a&gt;
Clone the repo and checkout the &amp;ldquo;solution&amp;rdquo; branch or use your own older solution&lt;/li&gt;
&lt;li&gt;Create a build folder, within which you write a Dockerfile for this service&lt;/li&gt;
&lt;li&gt;Write a Makefile which builds and tags the docker, and is able to push it to
a Docker registry&lt;/li&gt;
&lt;li&gt;Update the Makefile of your project to run the unit and integration tests
Inside the Docker you just created.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Solution:
&lt;a href=&#34;https://github.com/plain-vanilla-games/flask-test-kata/compare/solution...docker&#34;&gt;https://github.com/plain-vanilla-games/flask-test-kata/compare/solution...docker&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When completing this exercise you will likely run into a couple of issues with
the approach of having the &lt;code&gt;Dockerfile&lt;/code&gt; in a separate (&lt;code&gt;build&lt;/code&gt;) folder.  I solve
those issues by using a Makefile &amp;ndash; which in it&amp;rsquo;s most simple form could start
by copying the necessary files from &lt;code&gt;../&lt;/code&gt; and rm-ing them afterwards.&lt;/p&gt;

&lt;p&gt;Since at Plain Vanilla we always tag containers with the githash (commit) of the
code they contain, I decided to hit two birds with one stone, using either the
tip of the current branch or the githash given by the &lt;code&gt;GITHASH&lt;/code&gt; make parameter and
&lt;code&gt;git archive&lt;/code&gt; to deliver the code.&lt;/p&gt;

&lt;p&gt;Additionally, as new timestamps on &lt;code&gt;ADD&lt;/code&gt;-ed files will break the Docker cache I
am extracting the timestamp for the tip of the branch and setting the modification
date for some of the files to that.  Additionally I add requirements.txt manually
so that the &lt;code&gt;RUN pip install -r requirements.txt&lt;/code&gt; step can benefit from the Docker
cache.&lt;/p&gt;

&lt;p&gt;Your first, most basic version of the Makefile could be simpler &amp;ndash; and mine is not
without flaws, but I decided to employ some of the slightly more advanced methods
we use in order to expose some of the trickier parts of using Docker in production.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>brute force still going strong</title>
      <link>http://steinn.org/post/brute-force-still-going-strong/</link>
      <pubDate>Tue, 10 Feb 2015 21:08:21 +0000</pubDate>
      
      <guid>http://steinn.org/post/brute-force-still-going-strong/</guid>
      <description>&lt;p&gt;While setting up this blog I was looking through my little VMs scattered around
different cloud providers to find one which could serve as the A record for
&lt;code&gt;steinn.org&lt;/code&gt; and redirect traffic to &lt;code&gt;steinnes.github.io&lt;/code&gt;.  I logged on to one of my
&lt;a href=&#34;https://www.digitalocean.com&#34;&gt;digital ocean&lt;/a&gt; droplets that I haven&amp;rsquo;t used in
a while so I was slightly surprised to see more than 100k lines in &lt;code&gt;/var/log/auth.log&lt;/code&gt;.&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/16270.js&#34; id=&#34;asciicast-16270&#34; async&gt;&lt;/script&gt;

&lt;p&gt;I remember being a teenager and attempting to get access to random systems
I stumbled across on the internet.  I&amp;rsquo;m not going to lie, sometimes I&amp;rsquo;d get in
but the fear of being discovered was more than enough to prevent both any overt
attempts to connect, and to make sure if lucky enough to gain access, no damage
would be done.&lt;/p&gt;

&lt;p&gt;I have the distinct feeling something has changed since the late 90&amp;rsquo;s when I
was pretty much convinced that brute force attacks were just a stupid way to
get caught.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a little &lt;code&gt;iptables&lt;/code&gt;Â snippet if you&amp;rsquo;re wondering how I made my &lt;code&gt;auth.log&lt;/code&gt;
file stop growing:
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;iptables -F  &lt;span style=&#34;color: #75715e&#34;&gt;# flush&lt;/span&gt;

iptables -A INPUT -p tcp -s your-ip/32 --destination-port &lt;span style=&#34;color: #ae81ff&#34;&gt;22&lt;/span&gt; -j ACCEPT

iptables -A INPUT -p tcp -s 0.0.0.0/0 --destination-port &lt;span style=&#34;color: #ae81ff&#34;&gt;80&lt;/span&gt; -j ACCEPT
iptables -A INPUT -p tcp -s 0.0.0.0/0 --destination-port &lt;span style=&#34;color: #ae81ff&#34;&gt;443&lt;/span&gt; -j ACCEPT

iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

iptables -A INPUT -j REJECT  &lt;span style=&#34;color: #75715e&#34;&gt;# reject everything else&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Monolith to Services @ QuizUp</title>
      <link>http://steinn.org/post/utmessan2015/</link>
      <pubDate>Tue, 10 Feb 2015 11:44:14 +0000</pubDate>
      
      <guid>http://steinn.org/post/utmessan2015/</guid>
      <description>

&lt;p&gt;Last week I did a talk at a local IT conference, &lt;a href=&#34;https://www.utmessan.is&#34;&gt;UT Messan&lt;/a&gt;.
The title was the rather inflated &amp;ldquo;&lt;em&gt;From Monolith to Services at Scale: How
QuizUp is making the (inevitable?) transition, one endpoint at a time&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;In it I try to tell the story of how we at QuizUp are transitioning to a more
service-oriented architecture, and which steps we decided to take first.&lt;/p&gt;

&lt;p&gt;The route we chose was to use ZooKeeper as the heart of our system for
service registration, discovery and configuration, and then figure out how to
route client requests to services running inside Docker containers.  The
building blocks we ended up using were basically ZooKeeper, NGiNX, Docker, our
own Docker registries (which we refer to as &amp;ldquo;dockistries&amp;rdquo;), as well as a few
custom components which are outlined in the talk:&lt;/p&gt;

&lt;h2 id=&#34;video:72332d114d8f6408c00e9cd6db124848&#34;&gt;video&lt;/h2&gt;

&lt;p&gt;&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;700&#34; height=&#34;400&#34; src=&#34;http://www.youtube.com/embed/GhgH_8-HCVQ&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;h2 id=&#34;slides:72332d114d8f6408c00e9cd6db124848&#34;&gt;slides&lt;/h2&gt;

&lt;p&gt;&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;a36212c2dcc8418290d98ec6b9c0c8a1&#34; data-ratio=&#34;1.33333333333333&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;small&gt;*The slides here above are slightly updated from the ones I used during my talk.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;I would have liked to tell a bit more of a story, as we did create a couple
of services in the spring of 2014 which we always had issues deploying. After
some pondering we realized that without some kind of deployable packages (we
rolled our own, and also looked at using .deb), or standardized containers,
and a service registry we would probably end up with a lot of confusion (and
unexpected outages).  We decided on ZooKeeper, Docker and since we&amp;rsquo;re doing
that why not a dynamic router as well.&lt;/p&gt;

&lt;p&gt;Since the timeslot was only 30 minutes so I condensed this into 20-25 minutes
+ questions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>